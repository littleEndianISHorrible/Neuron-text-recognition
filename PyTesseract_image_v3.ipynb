{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: boxdetect in c:\\users\\maxik\\appdata\\roaming\\python\\python311\\site-packages (1.0.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\maxik\\appdata\\roaming\\python\\python311\\site-packages (from boxdetect) (4.9.0.80)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from boxdetect) (1.26.4)\n",
      "Requirement already satisfied: imutils in c:\\users\\maxik\\appdata\\roaming\\python\\python311\\site-packages (from boxdetect) (0.5.4)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from boxdetect) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from boxdetect) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->boxdetect) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->boxdetect) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->boxdetect) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boxdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "#from pdf2image import convert_from_path\n",
    "from wand.image import Image as WandImage\n",
    "from PyPDF2 import PdfReader\n",
    "from boxdetect import config\n",
    "from boxdetect.pipelines import get_checkboxes\n",
    "from colorama import Fore, Back, Style\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import Image, ImageFilter\n",
    "from xlsxwriter import workbook\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import openpyxl as xl\n",
    "import glob\n",
    "import os\n",
    "import openpyxl\n",
    "from numpy import asarray\n",
    "from openpyxl import load_workbook\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\maxik\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Users\\\\maxik\\\\AppData\\\\Local\\\\Programs\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your image (replace 'your_image.png' with th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_resolution(input_path, output_path, scale_factor):\n",
    "    with WandImage(filename=input_path) as img:\n",
    "        # Set resolution\n",
    "        img.resolution = (img.width * scale_factor, img.height * scale_factor)\n",
    "        # Save the high-resolution image\n",
    "        img.save(filename=output_path)\n",
    "def sharpen_image(input_path, output_path, factor=2):\n",
    "    # Open the image\n",
    "    image = Image.open(input_path)\n",
    "\n",
    "    # Apply the sharpen filter\n",
    "    sharpened_image = image.filter(ImageFilter.UnsharpMask(radius=2, percent=factor, threshold=1))\n",
    "\n",
    "    # Save the sharpened image\n",
    "    sharpened_image.save(output_path)\n",
    "def getboxcord(numpyarr, n=6):\n",
    "    verticle = np.sum(numpyarr, 0).tolist()\n",
    "    horrazontal = np.sum(numpyarr, 1).tolist()\n",
    "    v =verticle\n",
    "    h= horrazontal\n",
    "    verticle.sort()\n",
    "    horrazontal.sort()\n",
    "    verticleDuplicates = [verticle for verticle in verticle if verticle.count(verticle) > 1]\n",
    "    vunique_duplicates = list(set(verticleDuplicates))\n",
    "    horrazontalDuplicates = [horrazontal for horrazontal in horrazontal if horrazontal.count(horrazontal) > 1]\n",
    "    hunique_duplicates = list(set(horrazontalDuplicates))\n",
    "    topnv = vunique_duplicates[0:n]\n",
    "    topnh = hunique_duplicates[0:n]\n",
    "    x1=[]\n",
    "    y1=[]\n",
    "    x2=[]\n",
    "    y2=[]\n",
    "    x1[0:n].append((v.index(topnv[0:n]), h.index(topnh[0:n])))\n",
    "    y1[0:n].append((v.index(topnv[0:n]) + topnv[0:n], h.index(topnh[0:n])))\n",
    "    x2[0:n].append((v.index(topnv[0:n]), h.index(topnh[0:n])+ topnh[0:n]))\n",
    "    y2[0:n].append((v.index(topnv[0:n]) + topnv[0:n], h.index(topnh[0:n])+ topnh[0:n]))\n",
    "    print(y2)\n",
    "    print(list(v.index(topnv[0:n]) + topnv[0:n], h.index(topnh[0:n])+ topnh[0:n]))\n",
    "    lefts = []\n",
    "    rights = []\n",
    "    lower = []\n",
    "    upper = []\n",
    "\n",
    "def crop_item(dir, Le_Up_Ri_Lo, root_dir, left=0, upper=120, right=2000, lower=1000):\n",
    "    image = Image.open(dir)  # Replace with the path to your image\n",
    "        \n",
    "    # except:\n",
    "    #     print(dir+\" erro failed to read\")\n",
    "    #     return 1\n",
    "    # Define the coordinates of the rectangle you want to crop (left, upper, right, lower)\n",
    "    list_filename = dir.split('.')\n",
    "    filename=list_filename[0]+\".png\"\n",
    "    #^ nuron network to identify cordinates of a data frame rectangle, \n",
    "    # Crop the image\n",
    "    getboxcord(np.array(image))\n",
    "    if((image.width == right-left and image.width == lower-upper) or \"0\" in filename):\n",
    "        return filename\n",
    "    cropped_image = image.crop((left, upper, right, lower))\n",
    "    filename=list_filename[0]+\"0\"+\".png\"\n",
    "    # Save the cropped image\n",
    "    cropped_image.save(filename)\n",
    "    return filename\n",
    "def detect_horizontal_lines(img_array, threshold=0.95):\n",
    "    # Calculate the sum of pixel values along each row\n",
    "    row_sums = np.sum(img_array, axis=1)\n",
    "\n",
    "    # Detect horizontal lines by finding rows with pixel sums exceeding the threshold\n",
    "    horizontal_lines = np.where(row_sums >= threshold * img_array.shape[1])[0]\n",
    "    \n",
    "    return horizontal_lines\n",
    "\n",
    "\n",
    "def pdf_to_image_array(pdf_path, output_image_path, page_number=0):\n",
    "    output_filename = output_image_path.split(\".\")\n",
    "    output_filename = output_filename[0] + \"v6\"+\".png\"\n",
    "    print(output_filename)\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    page = pdf_document[page_number]\n",
    "    zoom = 4    # zoom factor\n",
    "    mat = fitz.Matrix(zoom, zoom)\n",
    "    image = page.get_pixmap(matrix = mat)\n",
    "    \n",
    "    \n",
    "    # Save the image to the specified path\n",
    "\n",
    "    image.save(output_filename, \"PNG\")\n",
    "    # Close the PDF document\n",
    "    #pdf_document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flashfill(x_seed, y_seed, img_path, color=(255, 255, 255, 255)):\n",
    "    img = Image.open(img_path)\n",
    "    img1 = img.convert(\"RGB\") \n",
    "    # Create an ImageDraw object\n",
    "    # Perform flood fill\n",
    "    ImageDraw.floodfill(img,(x_seed, y_seed), color)\n",
    "    # cv2.imshow('flash', asarray(img))\n",
    "    # # Break the loop if 'q' key is pressed\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     cv2.destroyAllWindows()\n",
    "    return np.array(img)\n",
    "def relative_flushFlood(img_path,relative_big_lines):\n",
    "    output_path = img_path.split()\n",
    "    output_path1 = output_path[0]+str(random.randint(0, 100)) + \".png\"\n",
    "    img = Image.open(img_path)\n",
    "    i=0\n",
    "    while(i<= 20):\n",
    "        x=random.randint(0, img.width)\n",
    "        try:\n",
    "            y=relative_big_lines[random.randint(0, len(relative_big_lines))]\n",
    "        except:\n",
    "            y=img.height\n",
    "        try:\n",
    "            if(img.getpixel((x,y)) == (0,0,0,0)):\n",
    "                pass\n",
    "            else:\n",
    "                modimg = Image.fromarray(flashfill(x, y, img_path), 'RGB')\n",
    "                modimg.save(img_path)\n",
    "                img=modimg\n",
    "        except:\n",
    "            pass\n",
    "        i+=1\n",
    "    return np.array(img)\n",
    "def precent(img_array):\n",
    "    viritile_lines = []\n",
    "    column_sums = []\n",
    "    column_sums = (np.sum(img_array, axis=0))\n",
    "    virticle_counter = 0\n",
    "    column_sums=list(column_sums)\n",
    "    try:\n",
    "        column_sums = [item for arr in column_sums for item in arr.tolist()]\n",
    "    except:\n",
    "        pass\n",
    "    #print(img_array)\n",
    "    #print(column_sums)\n",
    "    for i in column_sums:\n",
    "        if (i == min(column_sums)):\n",
    "            indices = np.where(column_sums == i)[0]\n",
    "            viritile_lines.extend(indices)\n",
    "            virticle_counter+=1\n",
    "    try:\n",
    "        precentage_virticle_white = (virticle_counter/len(column_sums)) *100\n",
    "    except:\n",
    "        precentage_virticle_white = 100\n",
    "    return precentage_virticle_white\n",
    "def margin_detect_verticle_lines(img_array, threshold=1.0):\n",
    "    # Calculate column sums\n",
    "    column_sums = np.sum(img_array, axis=0)\n",
    "    \n",
    "    # Sort indices based on column sums\n",
    "    sorted_indices = np.argsort(column_sums)\n",
    "    \n",
    "    # Threshold for significant vertical lines\n",
    "    threshold_value = threshold * max(column_sums)\n",
    "    \n",
    "    # Initialize lists for detected lines\n",
    "    vertical_lines = []\n",
    "    large_lines = []\n",
    "    \n",
    "    for i in column_sums:\n",
    "        if i >= threshold_value:\n",
    "            indices = np.where(column_sums == i)[0]\n",
    "            vertical_lines.extend(indices)\n",
    "            \n",
    "            # Check for large lines (you can adjust this condition)\n",
    "            if len(indices) > 10:  # Example: consider lines wider than 10 pixels\n",
    "                large_lines.extend(indices)\n",
    "    \n",
    "    # Calculate percentage of significant vertical white space\n",
    "    try:\n",
    "        percentage_vertical_white = (len(vertical_lines) / len(column_sums)) * 100\n",
    "    except ZeroDivisionError:\n",
    "        percentage_vertical_white = 0\n",
    "    vertical_lines=set(vertical_lines)\n",
    "    vertical_lines=list(vertical_lines)\n",
    "    vertical_lines.sort()\n",
    "    relative_verticle_lines = []\n",
    "    for k, g in groupby(enumerate(vertical_lines), lambda ix: ix[0] - ix[1]):\n",
    "        consecutive_numbers = list(map(itemgetter(1), g))\n",
    "        #print(consecutive_numbers)\n",
    "        relative_verticle_lines.append(int(sum(consecutive_numbers)/len(consecutive_numbers)))\n",
    "    return relative_verticle_lines, large_lines, percentage_vertical_white\n",
    "def is_image_black(img):\n",
    "    return not img.getbbox()\n",
    "def smart_crop_relative(image_path, output_path):\n",
    "    list_filename = image_path.split('.')\n",
    "    list_filename2=list_filename[0]+\"cropped\\\\\"\n",
    "    os.makedirs(list_filename2, exist_ok=True)\n",
    "    img1= Image.open(image_path).convert('L')\n",
    "    img = img1\n",
    "    img_array = np.array(img)\n",
    "    (relative_verticle_lines, relative_big_lines, precentage) = margin_detect_verticle_lines(img_array)\n",
    "    img = Image.fromarray(relative_flushFlood(image_path, relative_big_lines))\n",
    "    # relative_verticle_lines=set(relative_verticle_lines)\n",
    "    # relative_verticle_lines=list(relative_verticle_lines)\n",
    "    # relative_verticle_lines.sort()\n",
    "    print(relative_verticle_lines)\n",
    "    leftv = []\n",
    "    rightv = []\n",
    "    if(len(relative_verticle_lines) > 0):\n",
    "        rr = 0\n",
    "        ll = 0\n",
    "        #relative_verticle_lines.sort()\n",
    "        for rr in relative_verticle_lines:\n",
    "            up = 0\n",
    "            bottom = 1000\n",
    "                #img = img.resize((right, img.height))\n",
    "            if(ll>=rr):\n",
    "                ll=0\n",
    "                if(ll>=rr):\n",
    "                    rr=20\n",
    "            if(rr>=img.width):\n",
    "                new_image = Image.new(img.mode, (img.width+(rr-img.width), img.height))\n",
    "                new_image.paste(img, (0, 0))\n",
    "                img=new_image\n",
    "                # else:\n",
    "                #     new_image = Image.new(img.mode, (img.width+(img.width-rr), img.height))\n",
    "\n",
    "    # Paste the original image onto the new canvas\n",
    "            cropped_image = img.crop((ll, up, rr, bottom))\n",
    "            numpyarrCrppedimg=np.array(cropped_image)\n",
    "            value = precent(numpyarrCrppedimg)\n",
    "            value= int(value)\n",
    "            #print(\":value::\", value)\n",
    "            if(rr >= cropped_image.width):\n",
    "                new_image = Image.new(img.mode, (cropped_image.width+(rr-cropped_image.width), cropped_image.height))\n",
    "\n",
    "                new_image.paste(cropped_image, (0, 0))\n",
    "                cropped_image=new_image\n",
    "            if(value<=90):\n",
    "                filename=list_filename2+str(rr)+\".png\"\n",
    "                cropped_image.save(filename)\n",
    "                cv2.imshow\n",
    "                #display(cropped_image)\n",
    "        #     try:\n",
    "        #         cv2.imshow('Croppped img', asarray(cropped_image))\n",
    "        #     except:\n",
    "        #         pass\n",
    "        # # Break the loop if 'q' key is pressed\n",
    "        #     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #         break\n",
    "        #     try:\n",
    "        #         cv2.imshow('img', asarray(img))\n",
    "        #     except:\n",
    "        #         pass\n",
    "        # # Break the loop if 'q' key is pressed\n",
    "        #     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #         break\n",
    "            if(is_image_black(cropped_image)):\n",
    "                break\n",
    "            rightv.append(rr)\n",
    "    cv2.destroyAllWindows()\n",
    "    directory = list_filename[0]+\"cropped\\\\\"\n",
    "    file_list_cropped = os.listdir(directory)\n",
    "    file_list_cropped2= []\n",
    "    for i in file_list_cropped:\n",
    "        file_list_cropped2.append(directory+i)\n",
    "    file_list_cropped2.sort()\n",
    "    #print(file_list_cropped2)\n",
    "    for i in range(len(file_list_cropped2)):\n",
    "        #open i and i+1\n",
    "        try:\n",
    "            imgMain=Image.open(file_list_cropped2[i]).convert('L')\n",
    "            heavyvar = 0\n",
    "            if(i<=1):\n",
    "                heavyvar=rightv[0]\n",
    "            else:\n",
    "                heavyvar=rightv[rightv.index(imgMain.width)-1]\n",
    "            while(int(heavyvar)>imgMain.width and heavyvar>0):\n",
    "                heavyvar-=1\n",
    "            cropedMain = imgMain.crop((int(heavyvar), 0, imgMain.width, 1000))\n",
    "            cropedMain.save(file_list_cropped2[i])\n",
    "            #print(file_list_cropped2[i])\n",
    "            imgMain.close()\n",
    "        except:\n",
    "            #print(file_list_cropped2[i])\n",
    "            pass\n",
    "    return directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PrecentageMatch(string1, string2):\n",
    "    precetage_count = 0\n",
    "    for i in range(len(string1)):\n",
    "        #print(string1)\n",
    "        #print(string2)\n",
    "        try:\n",
    "            if(string1[i] == string2[i]):\n",
    "                precetage_count=+1\n",
    "        except:\n",
    "            precetage_count= precetage_count\n",
    "\n",
    "    if(precetage_count!=0):\n",
    "        return precetage_count/len(string1)*100\n",
    "    return 0\n",
    "def Compare(string1, string2):\n",
    "    '''\n",
    "    Compares two lists in a loop. Once the lists do not\n",
    "    match retures charater of lists that do not match.\n",
    "    '''\n",
    "\n",
    "    for i in range(len(string1)):\n",
    "        try:\n",
    "            if(string1[i] != string2[i]):\n",
    "                return string1\n",
    "        except:\n",
    "            pass\n",
    "    return \"error\"\n",
    "def match_join(string1, string2):\n",
    "    #print(string1)\n",
    "    #print(string2)\n",
    "    try:\n",
    "        string1_list = string1.split()\n",
    "    except:\n",
    "        print(\" \")\n",
    "        #print(\"except_string1\")\n",
    "    try:\n",
    "        string2_list = string2.split()\n",
    "    except:\n",
    "        #print(\"excelption_string2\")\n",
    "        print(\" \")\n",
    "    bitmap_append = []\n",
    "    output_string = \" \"\n",
    "    for i in range(len(string1_list)):\n",
    "        try:\n",
    "            if(string1_list[i] == string2_list[i]):\n",
    "                bitmap_append.append(1)\n",
    "            else:\n",
    "                bitmap_append.append(0)\n",
    "        except:\n",
    "            bitmap_append.append(0)\n",
    "    for j in range(len(bitmap_append)):\n",
    "        try:\n",
    "            if(bitmap_append[j]==1):\n",
    "                output_string = output_string+string2_list[j]\n",
    "        except:\n",
    "            pass\n",
    "    return output_string\n",
    "def create_scv(dir, filename_out, data_list, dir_outs):\n",
    "    if(len(data_list) <=1):\n",
    "        return 1\n",
    "    filename_outX = dir_outs+\".xlsx\"\n",
    "    df = pd.DataFrame(data_list)\n",
    "    print(filename_outX)\n",
    "    display(df)\n",
    "    df.to_excel(filename_outX)\n",
    "def combineONEXL(path, output):\n",
    "    #path = r'C:\\path\\to\\your\\directory'\n",
    "    print(path)\n",
    "# Get a list of all .xlsx files in the directory\n",
    "    file_list_cropped = os.listdir(path)\n",
    "    file_list_cropped2= []\n",
    "    for i in file_list_cropped:\n",
    "        file_list_cropped2.append(path+i)\n",
    "    files_xls= file_list_cropped2\n",
    "    print(files_xls)\n",
    "    # Initialize an empty DataFrame\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each file and append its data to the combined DataFrame\n",
    "    data = pd.DataFrame()\n",
    "    for file in files_xls:\n",
    "        data = pd.read_excel(file, sheet_name='Sheet1')  # Change 'Sheet1' to your sheet name\n",
    "        combined_df = pd.concat([combined_df, data], axis=1)\n",
    "        display(combined_df)\n",
    "        display(data)\n",
    "\n",
    "    # Now you have a single DataFrame containing data from all Excel files\n",
    "    combined_df.to_excel(output)\n",
    "    return path\n",
    "def pytesseractRead(dir, output_dir, sizeofDataframeROWSCOLS):\n",
    "    sharpen_image(dir, dir, 2)\n",
    "    print(dir)\n",
    "    image = Image.open(dir)  # Replace with the path to your image\n",
    "\n",
    "# Use pytesseract with custom configuration\n",
    "    text_colums = pytesseract.image_to_string(image, timeout=2)\n",
    "    custom_config = r'--psm 6'  # Horizontal text mode\n",
    "    text_lines = pytesseract.image_to_string(image, config=custom_config, timeout=2)\n",
    "    for i in text_lines:\n",
    "        if(i==\"\\n\" and (text_lines[text_lines.index(i)-1]==\"\\n\" or text_lines[text_lines.index(i)-1]==\" \")):\n",
    "            text_lines[text_lines.index(i)]=\"\"\n",
    "    for i in text_colums:\n",
    "        if(i==\"\\n\" and (text_colums[text_colums.index(i)-1]==\"\\n\" or text_colums[text_colums.index(i)-1]==\" \")):\n",
    "            text_colums[text_colums.index(i)]=\"\"\n",
    "\n",
    "    #creats lists\n",
    "    text_rows_inline = text_lines.split(\"\\n\")\n",
    "    text_colums_nline = text_colums.split(\"\\n\")\n",
    "    df = pd.DataFrame(text_colums_nline)\n",
    "    #print(datalistdf)\n",
    "    filename = output_dir.split(\"\\\\\")\n",
    "    create_scv(dir, filename[-1], df, output_dir)\n",
    "    return dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drg 09gyhrg 9uhregpiuhre gpiuh rgepiuh reg piuh rpiuhregpiuhgfreiuhregiuhrgeiuhrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:', 'Users', 'maxik', 'Documents', 'Github', 'Nuron-text-recognition', 'WNB-PUCD6-DH-1432-CVS']\n",
      "['C:', 'Users', 'maxik', 'Documents', 'Github', 'Nuron-text-recognition', 'WNB-PUCD6-DH-1432-CVS']\n",
      "C:\n",
      "C:\n",
      "Users\n",
      "C:\\Users\n",
      "maxik\n",
      "C:\\Users\\maxik\n",
      "Documents\n",
      "C:\\Users\\maxik\\Documents\n",
      "Github\n",
      "C:\\Users\\maxik\\Documents\\Github\n",
      "Nuron-text-recognition\n",
      "C:\\Users\\maxik\\Documents\\Github\\Nuron-text-recognition\n",
      "WNB-PUCD6-DH-1432-CVS\n",
      "C:\\Users\\maxik\\Documents\\Github\\Nuron-text-recognition\\WNB-PUCD6-DH-1432-CVS\n",
      "hello!\n",
      "hello\n",
      "extrancting\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[] is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m cvsDirout \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmaxik\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGithub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNuron-text-recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWNB-PUCD6-DH-1432-CVS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(cvsDirout, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(itr_dir(input_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, cvsDirout) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     85\u001b[0m     itr_dir(input_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, cvsDirout)\n",
      "Cell \u001b[1;32mIn[36], line 34\u001b[0m, in \u001b[0;36mitr_dir\u001b[1;34m(dir, extension, cvsDirout, jdg_dir)\u001b[0m\n\u001b[0;32m     32\u001b[0m list_filenames \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextrancting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m dir_20\u001b[38;5;241m=\u001b[39mcrop_item(dir_file, \u001b[38;5;241m0\u001b[39m, jdg_dir)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(dir_20\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrash\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 55\u001b[0m, in \u001b[0;36mcrop_item\u001b[1;34m(dir, Le_Up_Ri_Lo, root_dir, left, upper, right, lower)\u001b[0m\n\u001b[0;32m     52\u001b[0m filename\u001b[38;5;241m=\u001b[39mlist_filename[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#^ nuron network to identify cordinates of a data frame rectangle, \u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Crop the image\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m getboxcord(np\u001b[38;5;241m.\u001b[39marray(image))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m((image\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m right\u001b[38;5;241m-\u001b[39mleft \u001b[38;5;129;01mand\u001b[39;00m image\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m lower\u001b[38;5;241m-\u001b[39mupper) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "Cell \u001b[1;32mIn[33], line 33\u001b[0m, in \u001b[0;36mgetboxcord\u001b[1;34m(numpyarr, n)\u001b[0m\n\u001b[0;32m     31\u001b[0m x2\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     32\u001b[0m y2\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m---> 33\u001b[0m x1[\u001b[38;5;241m0\u001b[39m:n]\u001b[38;5;241m.\u001b[39mappend((v\u001b[38;5;241m.\u001b[39mindex(topnv[\u001b[38;5;241m0\u001b[39m:n]), h\u001b[38;5;241m.\u001b[39mindex(topnh[\u001b[38;5;241m0\u001b[39m:n])))\n\u001b[0;32m     34\u001b[0m y1[\u001b[38;5;241m0\u001b[39m:n]\u001b[38;5;241m.\u001b[39mappend((v\u001b[38;5;241m.\u001b[39mindex(topnv[\u001b[38;5;241m0\u001b[39m:n]) \u001b[38;5;241m+\u001b[39m topnv[\u001b[38;5;241m0\u001b[39m:n], h\u001b[38;5;241m.\u001b[39mindex(topnh[\u001b[38;5;241m0\u001b[39m:n])))\n\u001b[0;32m     35\u001b[0m x2[\u001b[38;5;241m0\u001b[39m:n]\u001b[38;5;241m.\u001b[39mappend((v\u001b[38;5;241m.\u001b[39mindex(topnv[\u001b[38;5;241m0\u001b[39m:n]), h\u001b[38;5;241m.\u001b[39mindex(topnh[\u001b[38;5;241m0\u001b[39m:n])\u001b[38;5;241m+\u001b[39m topnh[\u001b[38;5;241m0\u001b[39m:n]))\n",
      "\u001b[1;31mValueError\u001b[0m: [] is not in list"
     ]
    }
   ],
   "source": [
    "\n",
    "def itr_dir(dir, extension, cvsDirout, jdg_dir=r\"C:\\Users\\maxik\\Documents\\Github\\Nuron-text-recognition\\WNB-PUCD6-DH-1432-jdg\"):  # Replace with your desired file extension\n",
    "    # List all files in the directory\n",
    "\n",
    "    # Filter files by the specified extension\n",
    "    # Print the filtered file list\n",
    "    try:\n",
    "        file_list = os.listdir(jdg_dir)\n",
    "        filtered_files = [file for file in file_list if file.endswith(\".png\")]\n",
    "    except:\n",
    "        file_list = []\n",
    "        filtered_files = []\n",
    "    if(len(file_list) != 0 and len(filtered_files)!=0):\n",
    "        file_list = os.listdir(jdg_dir)\n",
    "        filtered_files = [file for file in file_list if file.endswith(\".png\")]\n",
    "        if(len(filtered_files) == 0):\n",
    "            return 1\n",
    "        dir_oututcvs = cvsDirout.split(\"\\\\\")\n",
    "        print(dir_oututcvs)\n",
    "        dir_out2 = dir_oututcvs[0:len(dir_oututcvs)]\n",
    "        print(dir_out2)\n",
    "        dir_outs = dir_out2[0]\n",
    "        for w in dir_out2:\n",
    "            print(w)\n",
    "            if(w!=dir_out2[0]):\n",
    "                dir_outs = dir_outs+\"\\\\\"+w\n",
    "            print(dir_outs)\n",
    "        print(\"hello!\")\n",
    "        for file in filtered_files:\n",
    "            dir_fle = \"\"\n",
    "            print(\"hello\")\n",
    "            dir_file = jdg_dir+'\\\\'+file\n",
    "            list_filenames = file.split('.')\n",
    "            print('extrancting')\n",
    "            dir_20=crop_item(dir_file, 0, jdg_dir)\n",
    "            if(dir_20==1):\n",
    "                print(\"crash\")\n",
    "                continue\n",
    "            ret =smart_crop_relative(dir_20,dir_20)\n",
    "            if(ret!= 1): \n",
    "                cropped_images = ret\n",
    "                print(cropped_images)\n",
    "                file_list_cropped = os.listdir(cropped_images)\n",
    "                file_list_cropped2= []\n",
    "                for d in file_list_cropped:\n",
    "                    file_list_cropped2.append(cropped_images+d)      \n",
    "                for q in file_list_cropped2:\n",
    "                    output_dir = q\n",
    "                    if(output_dir != 1):\n",
    "                        print(\"crop\")\n",
    "                        print(output_dir)\n",
    "                        filename = output_dir.split(\"\\\\\")\n",
    "                        files = filename[-1].split(\".\")\n",
    "                        dir_outcvs = cvsDirout+\"\\\\\"+file+\"\\\\\"\n",
    "                        print(\"sss\"+dir_outcvs)\n",
    "                        os.makedirs(dir_outcvs, exist_ok=True)\n",
    "                        pytesseractRead(output_dir, dir_outcvs+(files[0].split(\".\"))[0], (0,0))\n",
    "                        return 0\n",
    "                print(\"?????????????????????????????????????????????????????????????\")\n",
    "                combineONEXL(dir_outcvs, dir_outcvs+(file[0].split(\".\"))[0]+\".xlsx\") \n",
    "            else:\n",
    "                print(\"error\")\n",
    "        return 3\n",
    "    else:\n",
    "        file_list = os.listdir(dir)\n",
    "        filtered_files = [file for file in file_list if file.endswith(extension)]\n",
    "        os.makedirs(jdg_dir, exist_ok=True)\n",
    "        for file in filtered_files:\n",
    "            dir_file = \"\"\n",
    "            dir_file = dir+'\\\\'+file\n",
    "            list_filenames = file.split('.')\n",
    "            dir_filejpg = \"\"\n",
    "            dir_filejpg = jdg_dir+'\\\\'+file\n",
    "            if(list_filenames[-1] == \"pdf\"):\n",
    "                    #pdf_to_jpg(dir_file, dir)\n",
    "                    #extract_text_from_column(dir_file, 0)\n",
    "                pdf_to_image_array(dir_file, dir_filejpg)\n",
    "                #print(dir_file)\n",
    "        return 2\n",
    "input_dir=r\"C:\\Users\\maxik\\Documents\\GitHub\\Nuron-text-recognition\\WNB-PUCD6-DH-1432\"\n",
    "#input_dir=r\"C:\\Users\\maxik\\Documents\\GitHub\\Nuron-text-recognition\\support-right\"\n",
    "jdg_dir = r\"C:\\Users\\maxik\\Documents\\Github\\Nuron-text-recognition\\WNB-PUCD6-DH-1432-jdg\"\n",
    "cvsDirout = r\"C:\\Users\\maxik\\Documents\\Github\\Nuron-text-recognition\\WNB-PUCD6-DH-1432-CVS\"\n",
    "os.makedirs(cvsDirout, exist_ok=True)\n",
    "if(itr_dir(input_dir, \".pdf\", cvsDirout) == 2):\n",
    "    itr_dir(input_dir, \".pdf\", cvsDirout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
